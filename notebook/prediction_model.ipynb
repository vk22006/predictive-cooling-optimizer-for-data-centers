{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dff0aaf6",
   "metadata": {},
   "source": [
    "# Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ee3331",
   "metadata": {},
   "source": [
    "## Energy Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "442c30da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the Feature engineered Dataset and parse the timestamp column\n",
    "df_fe = pd.read_csv('dataset/HVAC Energy Data Feature Engineered.csv')\n",
    "timestamp_column = 'Local Time (Timezone : GMT+8h)'\n",
    "df_fe[timestamp_column] = pd.to_datetime(df_fe[timestamp_column])\n",
    "df_fe = df_fe.set_index(timestamp_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe1fa28",
   "metadata": {},
   "source": [
    "### Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41751387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Total samples: 13609\n",
      "✓ Number of features: 46\n",
      "✓ Target variable: Chiller Energy Consumption (kWh)\n",
      "\n",
      "✓ Training set: 10887 samples\n",
      "✓ Test set: 2722 samples\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import time\n",
    "\n",
    "# Define target and features\n",
    "target = 'Chiller Energy Consumption (kWh)'\n",
    "\n",
    "# Select relevant features (exclude target and original temporal columns)\n",
    "exclude_cols = [target, 'Hour', 'DayOfWeek', 'Month']  # Keep encoded versions\n",
    "feature_cols = [col for col in df_fe.columns if col not in exclude_cols]\n",
    "\n",
    "X = df_fe[feature_cols]\n",
    "y = df_fe[target]\n",
    "\n",
    "print(f\"\\n✓ Total samples: {len(X)}\")\n",
    "print(f\"✓ Number of features: {len(feature_cols)}\")\n",
    "print(f\"✓ Target variable: {target}\")\n",
    "\n",
    "# Train-test split (80-20, chronological)\n",
    "split_idx = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "print(f\"\\n✓ Training set: {len(X_train)} samples\")\n",
    "print(f\"✓ Test set: {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d70e8c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the test set for later evaluation\n",
    "X_test.to_csv('dataset/X_test_optimization_engine.csv', index=True)\n",
    "y_test.to_csv('dataset/y_test_optimization_engine.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff09c651",
   "metadata": {},
   "source": [
    "### XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d906f74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training XGBoost model...\n",
      "✓ Model trained in 3.67 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining XGBoost model...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Initialize XGBoost with simple, efficient parameters\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=200,      # Fewer trees for faster training\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    random_state=42,\n",
    "    n_jobs=-1             # Use all CPU cores\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "train_time = time.time() - start_time\n",
    "\n",
    "print(f\"✓ Model trained in {train_time:.2f} seconds\")\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_xgb = xgb_model.predict(X_train)\n",
    "y_test_pred_xgb = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c0ce39",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d5f70f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBOOST PERFORMANCE METRICS\n",
      "Training Set:\n",
      "  MAE:  0.632 kWh\n",
      "  RMSE: 0.880 kWh\n",
      "  R²:   0.9992\n",
      "\n",
      "Test Set:\n",
      "  MAE:  1.222 kWh\n",
      "  RMSE: 2.405 kWh\n",
      "  R²:   0.9842\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "train_mae_xgb = mean_absolute_error(y_train, y_train_pred_xgb)\n",
    "train_rmse_xgb = np.sqrt(mean_squared_error(y_train, y_train_pred_xgb))\n",
    "train_r2_xgb = r2_score(y_train, y_train_pred_xgb)\n",
    "\n",
    "test_mae_xgb = mean_absolute_error(y_test, y_test_pred_xgb)\n",
    "test_rmse_xgb = np.sqrt(mean_squared_error(y_test, y_test_pred_xgb))\n",
    "test_r2_xgb = r2_score(y_test, y_test_pred_xgb)\n",
    "\n",
    "print(\"XGBOOST PERFORMANCE METRICS\")\n",
    "print(f\"Training Set:\")\n",
    "print(f\"  MAE:  {train_mae_xgb:.3f} kWh\")\n",
    "print(f\"  RMSE: {train_rmse_xgb:.3f} kWh\")\n",
    "print(f\"  R²:   {train_r2_xgb:.4f}\")\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  MAE:  {test_mae_xgb:.3f} kWh\")\n",
    "print(f\"  RMSE: {test_rmse_xgb:.3f} kWh\")\n",
    "print(f\"  R²:   {test_r2_xgb:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2961ee9e",
   "metadata": {},
   "source": [
    "## Temperature Forecasting model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81cfc5b",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4841778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Forecast horizon: 2 time steps (1 hour)\n",
      "✓ Target: Future Cooling Water Temperature (C)\n",
      "✓ Dataset size after creating target: 13607 samples\n",
      "\n",
      "✓ Number of features: 46\n",
      "\n",
      "✓ Training set: 10885 samples\n",
      "✓ Test set: 2722 samples\n"
     ]
    }
   ],
   "source": [
    "# Create future temperature target (1 hour ahead = 2 steps)\n",
    "forecast_horizon = 2  # Predict 1 hour ahead\n",
    "temp_target = 'Cooling Water Temperature (C)'\n",
    "\n",
    "# Create shifted target\n",
    "df_temp = df_fe.copy()\n",
    "df_temp['Future_Temp'] = df_temp[temp_target].shift(-forecast_horizon)\n",
    "\n",
    "# Remove rows with missing future values\n",
    "df_temp = df_temp.dropna(subset=['Future_Temp'])\n",
    "\n",
    "print(f\"\\n✓ Forecast horizon: {forecast_horizon} time steps (1 hour)\")\n",
    "print(f\"✓ Target: Future {temp_target}\")\n",
    "print(f\"✓ Dataset size after creating target: {len(df_temp)} samples\")\n",
    "\n",
    "# Select features for temperature prediction\n",
    "temp_exclude = ['Future_Temp', temp_target, 'Hour', 'DayOfWeek', 'Month']\n",
    "temp_features = [col for col in df_temp.columns if col not in temp_exclude]\n",
    "\n",
    "X_temp = df_temp[temp_features]\n",
    "y_temp = df_temp['Future_Temp']\n",
    "\n",
    "print(f\"\\n✓ Number of features: {len(temp_features)}\")\n",
    "\n",
    "# Train-test split (80-20, chronological)\n",
    "split_idx = int(len(X_temp) * 0.8)\n",
    "X_train_temp, X_test_temp = X_temp[:split_idx], X_temp[split_idx:]\n",
    "y_train_temp, y_test_temp = y_temp[:split_idx], y_temp[split_idx:]\n",
    "\n",
    "print(f\"\\n✓ Training set: {len(X_train_temp)} samples\")\n",
    "print(f\"✓ Test set: {len(X_test_temp)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977de5c6",
   "metadata": {},
   "source": [
    "### XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b53c4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Model training completed in 2.11 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import xgboost as xgb\n",
    "\n",
    "# Initialize XGBoost model for temperature forecasting\n",
    "temp_model = xgb.XGBRegressor(\n",
    "    n_estimators=150,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "start_time = time.time()\n",
    "temp_model.fit(X_train_temp, y_train_temp)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n✓ Model training completed in {training_time:.2f} seconds\")\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_temp = temp_model.predict(X_train_temp)\n",
    "y_test_pred_temp = temp_model.predict(X_test_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5f8568",
   "metadata": {},
   "source": [
    "### Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4987456a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEMPERATURE FORECASTING MODEL PERFORMANCE\n",
      "\n",
      "\n",
      "TRAINING SET PERFORMANCE:\n",
      "  • MAE (Temperature):  0.331 °C\n",
      "  • RMSE (Temperature): 0.459 °C\n",
      "  • R² Score:           0.8615\n",
      "\n",
      "TEST SET PERFORMANCE:\n",
      "  • MAE (Temperature):  0.460 °C\n",
      "  • RMSE (Temperature): 0.655 °C\n",
      "  • R² Score:           0.6853\n",
      "TEMPERATURE PREDICTION ACCURACY (TOLERANCE BANDS)\n",
      "\n",
      "✓ Predictions within ±1.0°C:  89.24%\n",
      "✓ Predictions within ±0.5°C:  66.90%\n"
     ]
    }
   ],
   "source": [
    "train_mae_temp = mean_absolute_error(y_train_temp, y_train_pred_temp)\n",
    "train_rmse_temp = np.sqrt(mean_squared_error(y_train_temp, y_train_pred_temp))\n",
    "train_r2_temp = r2_score(y_train_temp, y_train_pred_temp)\n",
    "\n",
    "test_mae_temp = mean_absolute_error(y_test_temp, y_test_pred_temp)\n",
    "test_rmse_temp = np.sqrt(mean_squared_error(y_test_temp, y_test_pred_temp))\n",
    "test_r2_temp = r2_score(y_test_temp, y_test_pred_temp)\n",
    "\n",
    "print(\"TEMPERATURE FORECASTING MODEL PERFORMANCE\\n\")\n",
    "\n",
    "print(\"\\nTRAINING SET PERFORMANCE:\")\n",
    "print(f\"  • MAE (Temperature):  {train_mae_temp:.3f} °C\")\n",
    "print(f\"  • RMSE (Temperature): {train_rmse_temp:.3f} °C\")\n",
    "print(f\"  • R² Score:           {train_r2_temp:.4f}\")\n",
    "\n",
    "print(\"\\nTEST SET PERFORMANCE:\")\n",
    "print(f\"  • MAE (Temperature):  {test_mae_temp:.3f} °C\")\n",
    "print(f\"  • RMSE (Temperature): {test_rmse_temp:.3f} °C\")\n",
    "print(f\"  • R² Score:           {test_r2_temp:.4f}\")\n",
    "\n",
    "# Calculate accuracy within tolerance bands\n",
    "temp_diff = np.abs(y_test_pred_temp - y_test_temp)\n",
    "accuracy_1C = (temp_diff <= 1.0).mean() * 100\n",
    "accuracy_05C = (temp_diff <= 0.5).mean() * 100\n",
    "\n",
    "print(\"TEMPERATURE PREDICTION ACCURACY (TOLERANCE BANDS)\")\n",
    "print(f\"\\n✓ Predictions within ±1.0°C:  {accuracy_1C:.2f}%\")\n",
    "print(f\"✓ Predictions within ±0.5°C:  {accuracy_05C:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d01e1a3",
   "metadata": {},
   "source": [
    "## Saving Trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "129c8046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost models saved successfully to 'trained_models/xgboost_energy_model.pkl' and 'trained_models/xgboost_temperature_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Define the filename for saving the model\n",
    "model_filename = 'trained_models/xgboost_energy_model.pkl'\n",
    "model_filename_ = 'trained_models/xgboost_temperature_model.pkl'\n",
    "\n",
    "# Save the trained XGBoost model\n",
    "joblib.dump(xgb_model, model_filename)\n",
    "joblib.dump(temp_model, model_filename_)\n",
    "\n",
    "print(f\"XGBoost models saved successfully to '{model_filename}' and '{model_filename_}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
